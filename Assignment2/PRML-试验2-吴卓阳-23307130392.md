# **模式识别与机器学习 -- 实验2**

本实验包含以下部分：

-   softmax （50%） 

-   svm （50%）


## **softmax**

1 手动实现 Softmax 函数 （15%）
```
代码
max_values = logits.max(dim=-1, keepdim=True).values
exp_logits = torch.exp(logits - max_values)
sum_exp = exp_logits.sum(dim=-1, keepdim=True)
probs = exp_logits / sum_exp
return probs
```
说明

找出每一行的最大值；

用原始值减去每一行的最大值后，计算每一行每一个值的exp；

再计算每一行exp之后的和；

将每行exp之后的值，除以对应行exp后和的值，得到结果。



2 创建自定义 Softmax 层  （15%）

```
代码
def forward(self,x):
	return my_softmax(x)
	
self.network = nn.Sequential(
    nn.Linear(28 * 28, hidden1),
    nn.ReLU(),
    nn.Linear(hidden1, hidden2),
    nn.ReLU(),
    nn.Linear(hidden2, 10),
    MySoftmax()
)

def forward(self, x):
    x = self.flatten(x)
    probs = self.network(x)
    return probs
```
说明

在层封装中，定义前向传播逻辑为自己实现的softmax函数。

在自定义神经网络中，参考标准模型，写出一个三层全连接层的神经网络，在最后加入Softmax层。

在前向传播计算中，参考标准模型对数据进行处理，之后使用自己定义的神经网络进行计算，返回概率。



3 参数调优实验（无需给出代码）

​	通过参考“训练最佳模型”的代码，我们可以得到不同训练任务的代码模板。

​	我们需要做的就是在观测某一参数对于训练的影响时，先固定住其他参数，再将相应参数赋值为for循环中变化的变量，就可以得到该参数的不同取值对于训练的影响。

​	可以通过画图来具象化。



4 提交实验结果，只需截图最后的实验结果汇总和最佳模型的配置即可（20%）



## **svm**

### 一、损失和梯度的计算
#### 1, 循环实现中的梯度计算（10%）

补全 fduml.linear_svm import中的svm_loss_naive函数

在这里写代码，并简单说明（注意，没有说明会适当扣分）

```
代码
```
说明

#### 2, 向量实现中的损失计算和梯度计算（15%）

补全 fduml.linear_svm import中的svm_loss_vectorized函数

在这里写代码，并简单说明

```
代码
```
说明

#### 3, 在这里提交ipynb中的相关检查结果（不占额外分数，但这是判断上面的实现是否正确的重要依据



### 二、实现SGD 
代码+简单说明（10%）

```
代码
```
说明

### 三、利用验证集做超参数调优 
表格记录（5*5），可以自己尝试不同的组合 （10%）

| 学习率 \ 正则化强度 | 0.001       | 0.01        | 0.1         | 1.0         | 10.0        |
| :----------------- | :---------- | :---------- | :---------- | :---------- | :---------- |
| **0.0001**         | {结果}      | {结果}      | {结果}      | {结果}      | {结果}      |
| **0.001**          | {结果}      | {结果}      | {结果}      | {结果}      | {结果}      |
| **0.01**           | {结果}      | {结果}      | {结果}      | {结果}      | {结果}      |
| **0.1**            | {结果}      | {结果}      | {结果}      | {结果}      | {结果}      |
| **1.0**            | {结果}      | {结果}      | {结果}      | {结果}      | {结果}      |

最优的结果的loss曲线截图和正确率截图（5%）



